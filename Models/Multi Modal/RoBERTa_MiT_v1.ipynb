{"cells":[{"cell_type":"markdown","metadata":{"id":"EqVJQTs4DlzY"},"source":["### 0. 라이브러리"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","\n","# OS 충돌 방지\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","# Matplotlib 커널 종료 방지\n","os.environ['KMP_DUPLICATE_LIB_OK']='True'"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Nr0KPhWGDnVb"},"outputs":[],"source":["# 라이브러리\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import os\n","import time\n","import pickle\n","import random\n","import zipfile\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from PIL import Image\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n","from torchsummary import summary\n","\n","from torchvision import transforms\n","\n","import transformers\n","from transformers import AutoTokenizer, AutoModel, AutoImageProcessor, SegformerModel, get_linear_schedule_with_warmup\n","\n","from peft import get_peft_model, LoraConfig, TaskType"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"YPN68sI5Drbi"},"outputs":[],"source":["# 시드 고정\n","def fixSEED(seed, deterministic=True):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    if deterministic:\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","seed = 42\n","fixSEED(seed=seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1718000649114,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"voCRFRa3DyF2","outputId":"1b96e9b3-134e-4176-e527-bc1edacc10fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current path /content/drive/MyDrive/Projects/Model/YouTube_Image\n"]}],"source":["# 디렉토리 설정\n","dir = 'Python_Programs'\n","path = '/home/leesanghyuk2000/' + dir\n","os.chdir(path)\n","print('Current path {}'.format(os.getcwd()))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1718000649114,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"fSENXdxUDzxX","outputId":"686b5a95-bcda-4243-d5be-1d490062794c"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# GPU 사용 여부 확인\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"hjYVCqKzEidx"},"source":["### 1. 썸네일 데이터 압축 해제"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"FSATiTBCEnR9"},"outputs":[],"source":["def unzip_file(zip_path, extract_path):\n","    # 압축 해제할 디렉토리가 존재하지 않으면 생성\n","    if not os.path.exists(extract_path):\n","        os.makedirs(extract_path)\n","\n","    # zipfile 모듈을 사용하여 압축 해제\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(zip_path)\n","\n","    print(f'Complete Unzipping to {extract_path}')"]},{"cell_type":"markdown","metadata":{"id":"nOOnd47UF0AP"},"source":["### 2. 텍스트 데이터 가져오기"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"SQWletEOF1c9"},"outputs":[],"source":["# 데이터 불러오기\n","with open('youtubeData(8331)_with_label.pkl', 'rb') as f:\n","    data = pickle.load(f)"]},{"cell_type":"markdown","metadata":{"id":"DGjm2cvVGrvS"},"source":["### 3. 썸네일이 없는 경우 확인"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1718000847935,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"CdyAwyDFGv6V","outputId":"5925196b-b4f7-4188-9b5f-edeaf35a8182"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>youtuber</th>\n","      <th>my_label</th>\n","      <th>channel_id</th>\n","      <th>title</th>\n","      <th>video_id</th>\n","      <th>thumbnail</th>\n","      <th>content</th>\n","      <th>saved</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [youtuber, my_label, channel_id, title, video_id, thumbnail, content, saved, label]\n","Index: []"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# 썸네일 이미지가 없는 데이터 있는지 확인\n","data[data['saved'] == 0]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2110,"status":"ok","timestamp":1718001012297,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"-c1G1HDHHc76","outputId":"d3cd8bd4-7895-4ff8-e6fa-2db7fc054176"},"outputs":[{"name":"stderr","output_type":"stream","text":["Checking thumbnails: 100%|██████████| 8331/8331 [00:00<00:00, 18176.61it/s]\n"]}],"source":["# 열 생성\n","data['drive_saved'] = 0\n","\n","# 썸네일 파일 경로\n","thumbnail_path = 'Thumbnails/Thumbnails'\n","\n","# 각 video_id에 대해 파일 존재 여부 확인\n","for i in tqdm(data.index, desc=\"Checking thumbnails\"):\n","    video_id = data.at[i, 'video_id']\n","    file_path = os.path.join(thumbnail_path, f\"{video_id}.jpg\")\n","    if os.path.isfile(file_path):\n","        data.at[i, 'drive_saved'] = 1"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1718001014603,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"PiMWBnv5HpXk","outputId":"d0066b7b-8aab-445a-c068-bacf9dd2170b"},"outputs":[{"data":{"text/plain":["drive_saved\n","1    8331\n","Name: count, dtype: int64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# 확인\n","data['drive_saved'].value_counts()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1718001028217,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"rVlu_BhyJgQx","outputId":"05e9a612-1fa1-4ff8-f04b-a86456fc27fa"},"outputs":[{"data":{"text/plain":["label\n","0    5208\n","1    3123\n","Name: count, dtype: int64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# 레이블 개수 확인\n","data['label'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"mKA0urL2StUc"},"source":["### 4. Train/Valid/Test 분리"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"_s3AhH4HSwEq"},"outputs":[],"source":["# Split into Train/Valid/Test\n","def splitData(data, SEED=42):\n","    train_val_data, test_data = train_test_split(data, test_size=0.2, random_state=SEED, stratify=data['label'])\n","    train_data, valid_data = train_test_split(train_val_data, test_size=0.25, random_state=SEED, stratify = train_val_data['label'])\n","\n","    print('학습용 데이터 개수 : {}개 \\n검증용 데이터 개수 : {}개 \\n평가용 데이터 개수 : {}개'.format(len(train_data), len(valid_data), len(test_data)))\n","    del train_val_data\n","    return train_data, valid_data, test_data"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718001206467,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"x2JEj8C5Sxc_","outputId":"942b9b44-43bb-4dda-d57e-33f31cfb0495"},"outputs":[{"name":"stdout","output_type":"stream","text":["학습용 데이터 개수 : 4998개 \n","검증용 데이터 개수 : 1666개 \n","평가용 데이터 개수 : 1667개\n"]}],"source":["train_data, valid_data, test_data = splitData(data)"]},{"cell_type":"markdown","metadata":{"id":"Zh3GApCJIU-_"},"source":["### 5. Datasets 및 Dataloader 정의"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"rVba8PJtIYy3"},"outputs":[],"source":["# 파라미터 개수 확인\n","def print_trainable_parameters(model):\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(f\"Trainable Params: {trainable_params} \\nAll params: {all_param}\")\n","    print('-'*50)\n","    print(f\"Trainable(%): {round(100 * trainable_params / all_param, 5)}\")"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"rdK003aOIaOT"},"outputs":[],"source":["# Multi-modal Dataset\n","class MultiModalDataset(Dataset):\n","    def __init__(self, dataframe, text_tokenizer, max_length, image_processor, image_path, transform=None):\n","        self.data = dataframe\n","        self.text_tokenizer = text_tokenizer\n","        self.max_length = max_length\n","        self.image_processor = image_processor # MiT-b0 사용을 위해 수정\n","        self.image_path = image_path\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        title = self.data.iloc[idx]['title'] # 제목\n","        content = self.data.iloc[idx]['content'] # 내용\n","        text = title + ' ' + content # 제목 + 내용\n","        video_id = self.data.iloc[idx]['video_id'] # 영상 ID\n","        label = self.data.iloc[idx]['label']\n","\n","        # text 토크나이저\n","        text_inputs = self.text_tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=self.max_length)\n","        input_ids = text_inputs['input_ids'].squeeze(0)\n","        attention_mask = text_inputs['attention_mask'].squeeze(0)\n","\n","        # image 불러오기 및 전처리\n","        img_path = os.path.join(self.image_path, f\"{video_id}.jpg\")\n","        if self.transform is not None:\n","            image = self.transform(Image.open(img_path))\n","        else:\n","            image = Image.open(img_path)\n","\n","        # image Feature Extract\n","        image_inputs = self.image_processor(images=image, return_tensors='pt')\n","        pixel_values = image_inputs['pixel_values'].squeeze(0)\n","\n","        return input_ids, attention_mask, pixel_values, torch.tensor(label, dtype=torch.long)  # 정수형"]},{"cell_type":"markdown","metadata":{"id":"slb-_hRMLGLh"},"source":["### 6. 모델 정의"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"vNr1bTW3L2Ot"},"outputs":[],"source":["class RoBERTawithMiT(nn.Module):\n","    def __init__(self, text_checkpoint, vision_checkpoint, lora_r=8, lora_alpha=1, lora_dropout=0.1):\n","        super(RoBERTawithMiT, self).__init__()\n","\n","        # Pre-trained model for text and image\n","        self.text_model = AutoModel.from_pretrained(text_checkpoint, output_hidden_states=True)\n","        self.img_model = SegformerModel.from_pretrained(vision_checkpoint) # SegformerForImageClassification가 아닌 Model을 사용\n","\n","        # LoRA Config for text model\n","        text_config = LoraConfig(\n","            target_modules=[\"query\", \"key\", \"value\"],  # Apply LoRA to the all attention layers\n","            r=lora_r,\n","            lora_alpha=lora_alpha,\n","            lora_dropout=lora_dropout\n","        )\n","\n","        # LoRA Config for image model\n","        img_config = LoraConfig(\n","            target_modules=[\"query\", \"key\", \"value\"],  # Apply LoRA to the all attention layers\n","            r=lora_r,\n","            lora_alpha=lora_alpha,\n","            lora_dropout=lora_dropout,\n","        )\n","\n","        # Apply LoRA to each models\n","        self.text_model = get_peft_model(self.text_model, text_config)\n","        self.img_model = get_peft_model(self.img_model, img_config)\n","\n","        # Transformer Encoder for cancat outputs\n","        self.encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=self.text_model.config.hidden_size + self.img_model.config.hidden_sizes[-1],\n","            nhead=8\n","        )\n","        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1) # 트랜스포머 인코더는 1개만 이용\n","\n","        # Classifier layer\n","        self.classifier = nn.Linear(self.text_model.config.hidden_size + self.img_model.config.hidden_sizes[-1], 2)\n","\n","        # Dropout\n","        self.dropout = nn.Dropout(p=0.1)\n","\n","    def forward(self, input_ids, attention_mask, pixel_values):\n","        # Text model 순전파\n","        text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n","        text_hidden_state = text_outputs.hidden_states[-1][:, 0, :]  # CLS token\n","\n","        # Image model 순전파\n","        img_outputs = self.img_model(pixel_values=pixel_values)\n","        img_hidden_state = img_outputs.last_hidden_state[:, 0, :]  # CLS token\n","\n","        # image, text 모델의 결과 concat\n","        concat_hidden_state = torch.cat((text_hidden_state, img_hidden_state), dim=1).unsqueeze(1)\n","\n","        # concat 결과를 encoder에 전달\n","        encoded_output = self.transformer_encoder(concat_hidden_state)\n","        encoded_output = encoded_output[:, 0, :]  # CLS token\n","\n","        # 드롭아웃 적용\n","        encoded_output = self.dropout(encoded_output)\n","\n","        # encoder에 결과를 classifier로 전달\n","        logits = self.classifier(encoded_output)\n","\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"yLOepSJRR2RL"},"source":["모델 정의 참고\n","\n","1. SegformerModel : https://huggingface.co/nvidia/mit-b0\n","2. SegformerForImageClassification : https://huggingface.co/nvidia/mit-b0"]},{"cell_type":"markdown","metadata":{"id":"6usFECLBR-yi"},"source":["### 7. 학습용 Trainer 정의"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"fh1W5zLNR5z0"},"outputs":[],"source":["class Trainer:\n","    def __init__(self, model, train_dataloader, valid_dataloader, criterion, optimizer, acc_metric, precision_metric, recall_metric, f1_metric, device, num_epochs, wait_for_es):\n","        self.model = model  # model for training\n","        self.train_dataloader = train_dataloader  # training dataloader\n","        self.valid_dataloader = valid_dataloader  # validation dataloader\n","        self.criterion = criterion  # loss function\n","        self.optimizer = optimizer  # optimizer\n","        self.acc_metric = acc_metric  # accuracy metric\n","        self.precision_metric = precision_metric  # precision metric\n","        self.recall_metric = recall_metric  # recall metric\n","        self.f1_metric = f1_metric  # f1 score metric\n","        self.device = device  # device(cuda or cpu)\n","        self.num_epochs = num_epochs  # number of epochs\n","        self.wait_for_es = wait_for_es  # early stopping patience\n","        \n","        # 스케줄러 초기화\n","        total_steps = len(train_dataloader) * num_epochs\n","        self.scheduler = get_linear_schedule_with_warmup(self.optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","\n","    def train(self):\n","        train_loss_history, train_acc_history, train_precision_history, train_recall_history, train_f1_history = [], [], [], [], []\n","        valid_loss_history, valid_acc_history, valid_precision_history, valid_recall_history, valid_f1_history = [], [], [], [], []\n","\n","        best_loss = float('inf')\n","        count = 0\n","        best_acc = 0\n","        start_time = time.time()\n","\n","        for epoch in range(self.num_epochs):\n","            print('-' * 80)\n","            print(f'Epoch {epoch+1}/{self.num_epochs}')\n","            print('-' * 80)\n","\n","            train_loss, train_acc, train_precision, train_recall, train_f1 = self._train_model()\n","            valid_loss, valid_acc, valid_precision, valid_recall, valid_f1 = self._valid_model()\n","\n","            train_loss_history.append(train_loss)\n","            train_acc_history.append(train_acc)\n","            train_precision_history.append(train_precision)\n","            train_recall_history.append(train_recall)\n","            train_f1_history.append(train_f1)\n","\n","            valid_loss_history.append(valid_loss)\n","            valid_acc_history.append(valid_acc)\n","            valid_precision_history.append(valid_precision)\n","            valid_recall_history.append(valid_recall)\n","            valid_f1_history.append(valid_f1)\n","\n","            elapsed_time = time.time() - start_time\n","            print(f'[Train] \\t Loss: {train_loss:.4f} \\t Acc: {train_acc:.4f} \\t Precision: {train_precision:.4f} \\t Recall: {train_recall:.4f} \\t F1: {train_f1:.4f}')\n","            print(f'[Valid] \\t Loss: {valid_loss:.4f} \\t Acc: {valid_acc:.4f} \\t Precision: {valid_precision:.4f} \\t Recall: {valid_recall:.4f} \\t F1: {valid_f1:.4f}')\n","            print(f'(Epoch {epoch+1} complete in {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s)')\n","\n","            if valid_acc > best_acc:\n","                best_acc = valid_acc\n","                try:\n","                    save_path = f'./YouTube_RoBERTa_MiT_ACC_{valid_acc:.4f}.pth'\n","                    torch.save(self.model.state_dict(), save_path)\n","                    print(f'Model Saved to {save_path}')\n","                except:\n","                    print('Model Not Saved')\n","                    continue\n","\n","            if valid_loss < best_loss:\n","                best_loss = valid_loss\n","                count = 0\n","            else:\n","                count += 1\n","                if count >= self.wait_for_es:\n","                    print(f'Early Stopping at Epoch {epoch+1}')\n","                    break\n","\n","        return train_loss_history, train_acc_history, train_precision_history, train_recall_history, train_f1_history, valid_loss_history, valid_acc_history, valid_precision_history, valid_recall_history, valid_f1_history\n","\n","    # Training function\n","    def _train_model(self):\n","        self.model.train()\n","\n","        train_loss = 0\n","        train_acc = 0\n","        train_precision = 0\n","        train_recall = 0\n","        train_f1 = 0\n","\n","        for batch in tqdm(self.train_dataloader, desc='Training'):\n","            input_ids, attention_mask, pixel_values, y = batch\n","            input_ids, attention_mask, pixel_values, y = input_ids.to(self.device), attention_mask.to(self.device), pixel_values.to(self.device), y.to(self.device)\n","\n","            outputs = self.model(input_ids, attention_mask, pixel_values)\n","            loss = self.criterion(outputs, y) # 데이터셋에서 레이블을 long으로 정의함\n","\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","            self.scheduler.step()  # 스케줄러 업데이트\n","\n","            preds = torch.argmax(outputs, dim=1)\n","            train_loss += loss.item()\n","            train_acc += self.acc_metric(preds, y).item()\n","            train_precision += self.precision_metric(preds, y).item()\n","            train_recall += self.recall_metric(preds, y).item()\n","            train_f1 += self.f1_metric(preds, y).item()\n","\n","        return train_loss / len(self.train_dataloader), train_acc / len(self.train_dataloader), train_precision / len(self.train_dataloader), train_recall / len(self.train_dataloader), train_f1 / len(self.train_dataloader)\n","\n","    # Validating function\n","    def _valid_model(self):\n","        self.model.eval()\n","\n","        valid_loss = 0\n","        valid_acc = 0\n","        valid_precision = 0\n","        valid_recall = 0\n","        valid_f1 = 0\n","\n","        with torch.no_grad():\n","            for batch in tqdm(self.valid_dataloader, desc='Validating'):\n","                input_ids, attention_mask, pixel_values, y = batch\n","                input_ids, attention_mask, pixel_values, y = input_ids.to(self.device), attention_mask.to(self.device), pixel_values.to(self.device), y.to(self.device)\n","\n","                outputs = self.model(input_ids, attention_mask, pixel_values)\n","                loss = self.criterion(outputs, y)\n","\n","                preds = torch.argmax(outputs, dim=1)\n","                valid_loss += loss.item()\n","                valid_acc += self.acc_metric(preds, y).item()\n","                valid_precision += self.precision_metric(preds, y).item()\n","                valid_recall += self.recall_metric(preds, y).item()\n","                valid_f1 += self.f1_metric(preds, y).item()\n","\n","        return valid_loss / len(self.valid_dataloader), valid_acc / len(self.valid_dataloader), valid_precision / len(self.valid_dataloader), valid_recall / len(self.valid_dataloader), valid_f1 / len(self.valid_dataloader)"]},{"cell_type":"markdown","metadata":{"id":"mR6NaykNSDW9"},"source":["### 8. 학습 설정"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["5bdac34142f44af494316c16b72cfb12","96cf0b7cd2054a44afb1f8d08fbb23db","6004a9763595414bb448e93736855d22","f1b0ab561bfa41b5a73cdba015a8a8de","578e388fc32642e5ac305b8381ac1e4a","69ae0998628e422eb96470e4ad655f09","cb5e76fc03584709a8e94de68c3e97c3","f25e3f27104747a3823ac47d1bf89d4d","94cecbf9794c49fdad80d7527365357a","1ad561646a1f44faaf62e1e193133c32","792c5c05251f4b34aef67fdf8b6567a1","920bb65bedbc43888a2a97b65a02dd91","69edc96c74624b3bb2b0119168aefedd","0ddd353782a4448881a68400fadf4288","8dcfafcec94746cfb0d7a03fbef79fbe","90b7dee96efc4df89e1975f5df903925","1e03c962ba894ca3a08203fd853f2e60","19001101177f465eaabaf7ba4948bc6e","275a743ae76f4ec5ba6e4dfff871b8f8","cbb0b5836e5e44dc8aa4eec94c76e906","b08acb98d58f4a8692030f0b875b6289","b2f242ac94284a8bbb3d575387d70e54","347a8274bdb54ca8a5a7e89b48870129","533b5eaeb77349cf99fe9b4f841d3792","f2cf3f33489142749d7679ffeea51270","0624914bb8e441b489c5b02b718e5d9a","22299453ce11485aaef6f7acae14e9d8","ceb3f06c3e474dac9288978a208e057c","51f8b03224f140bb857153483e96842d","6435fffa801b449ba5df6b2cc4150298","269796c6b7034c7099f967abf92ae7ec","d413c7e62d594a1b9d3478c929785462","cdca1e7573304150bdfd739f9e193cce","ab122c513e1f4010974bad603d341782","0ec6d0d8c7ec4e6e84c1db64e0dab5fa","a66dcfc200f34bafa7738af46574b6fb","38272f22ffef4216926f30ea7dabc470","b4ec8ccc5ba44233bff06c203893beb1","8b706de7f1974d019f00c0886c040c93","49c7892db8de4de68803fb3d6f687371","89850ceba93d4524a01f42a569c83e13","91344e321a9b455d8f0624d03288b5eb","6fe64ed868a8449b8a93afa368c9ace2","1f398eb7136b4c7f95dc7987db6ecafa","a6d5ee785f9040cb9da60ec576f82e53","2e8c3c52ad1b468c82615f89e14826b1","e76c9795113848dca5d946aae0374804","27eed056870f44e6b33faa35edbceb9c","fcab8208928944efb75f604862361f54","2316a1c3d2b84c94ba3b816e468fcc8e","b400db3135534cc8862f474e72b2fb52","327914875a464c828f73a942b7a6a76d","114c621ffd2f43eaaefc5bbe02f5e4cf","f6dc1702c30b4b56b231ecb67511abf2","05ad48b549a74363b45ed162195f23f4"]},"executionInfo":{"elapsed":6984,"status":"ok","timestamp":1718001721079,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"Vpml_WijSG7k","outputId":"c228ec99-baa9-42ed-b17e-75896defe1fb"},"outputs":[],"source":["# 데이터셋 파라미터\n","batch_size = 32\n","num_labels = 2\n","max_length = 64\n","\n","# text 토크나이저 정의\n","text_checkpoint = \"klue/roberta-large\"\n","tokenizer = AutoTokenizer.from_pretrained(text_checkpoint)\n","\n","# image 프로세서 정의\n","vision_checkpoint = \"nvidia/mit-b0\"\n","feature_extractor = AutoImageProcessor.from_pretrained(vision_checkpoint)\n","\n","# image 경로\n","image_path = 'Thumbnails/Thumbnails'"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"qrM6xpWZ4c_m"},"outputs":[],"source":["# 이미지 전처리 객체\n","transform = transforms.Compose(\n","    [\n","        #transforms.Resize([256, 256]), # 이미지를 크기를 조정\n","        #transforms.RandomCrop([224, 224]), # 이미지를 랜덤하게 자르기\n","        #transforms.RandomResizedCrop(256), # 이미지를 랜덤한 크기로 자르고 크기를 조정\n","        transforms.RandomHorizontalFlip(), # 이미지를 랜덤하게 수평으로 뒤집기\n","        transforms.RandomVerticalFlip(), # 이미지를 랜덤하게 수직으로 뒤집기\n","        #transforms.RandomRotation(45), # 이미지를 랜덤하게 회전\n","        transforms.ToTensor(), # 이미지를 텐서로 변환\n","        #transforms.Grayscale(num_output_channels=1), # 이미지를 흑백으로 변환\n","        #transforms.Normalize((0.5,), (0.5,)), # 이미지를 정규화(ToTensor 다음에 사용)\n","        #transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1) # 이미지의 밝기, 대비, 채도, 색상을 무작위로 조정\n","])"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"KFsvd20NSkAy"},"outputs":[],"source":["# 데이터셋 정의\n","train_dataset = MultiModalDataset(train_data, tokenizer, max_length, feature_extractor, image_path, transform)\n","valid_dataset = MultiModalDataset(valid_data, tokenizer, max_length, feature_extractor, image_path, transform)\n","test_dataset = MultiModalDataset(test_data, tokenizer, max_length, feature_extractor, image_path, transform)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1718001891341,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"GeMwgtrRTsmt","outputId":"e1d1aabd-7826-438d-b71d-ec9dc83dc234"},"outputs":[{"data":{"text/plain":["[tensor([[    0,   114, 10292,  ...,  8594, 12190,     2],\n","         [    0,  6775,  2226,  ...,  4129,  5017,     2],\n","         [    0,  8309,  2170,  ...,  2259,  1521,     2],\n","         ...,\n","         [    0,    12,  1263,  ...,  1545,  2116,     2],\n","         [    0, 22042,  2116,  ...,  2119, 18008,     2],\n","         [    0,  3629,   864,  ...,  2200,  1238,     2]]),\n"," tensor([[1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         ...,\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1]]),\n"," tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           ...,\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n"," \n","          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           ...,\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n"," \n","          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           ...,\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n"," \n"," \n","         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           ...,\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n"," \n","          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           ...,\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n"," \n","          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           ...,\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n"," \n"," \n","         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           ...,\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n"," \n","          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           ...,\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n"," \n","          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           ...,\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n"," \n"," \n","         ...,\n"," \n"," \n","         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           ...,\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n"," \n","          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           ...,\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n"," \n","          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           ...,\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n"," \n"," \n","         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           ...,\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n"," \n","          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           ...,\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n"," \n","          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           ...,\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n"," \n"," \n","         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           ...,\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n","           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n"," \n","          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           ...,\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n"," \n","          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           ...,\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n","           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]]),\n"," tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n","         0, 0, 0, 0, 0, 0, 0, 1])]"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# 데이터로더 정의\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","next(iter(train_dataloader))"]},{"cell_type":"markdown","metadata":{"id":"4fVq3YwTbILC"},"source":["### 9. 학습 진행"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5ab57db8244546b9b4fa74d887e4a7c5","c55426784c884206bd9ec6b2778868a6","349b0743813c449e90c56bef8eacb9a1","d4613f0edca84df7a62d0329f910ca55","e1418eb477114bc697cfd013353ebf4e","fbcc5b2ac63f4fbd828307b3df0ae007","cd12fd03a5e94f6284ee141001595d8c","b58b8e79716745b8b370074f07d03cf0","0e0a1902e72a4cd282ea551dd2de7f63","494c8c49bb4342428114da3ffa7faf7e","6bfdbce1e7594fd59f8d481ba30abfd5","fccf9be0b52f4cc1b1e3f755422d7693","e5ce1d91567f4c949cfea93b72f4478e","ab065a9873244e40a6b6390e0547245c","bf59ec9765844db09f7ca03fe1e1355b","7e35e6e83b084964b8a7458c0e7fda42","5e70b95e73cf45f6bd58628862e2627a","c8ab35e93fd34caf996c05ca0f46baba","8ef1d75b9c8841a5b9dbd2b40b3f74f3","d909c83b089b4c29a7f42eab7c8d31c8","431181882470458c861b502da88cbbc3","b83f9b62de3d4646a6bf81edd8e34f9b","8e363762c5be48b6bfe9fedb52f9e05e","2c14ffbc9af94a86969e4bb355c0f8cd","0e8eab51253140cab747ea43c82e1493","34faa1f4ba3842ab9e718dec8f5191d3","8b9a4796504640a39f88de8ecd02f016","d5c6cfdfaa644a81ba362a0a91cfe80f","2d58d9d9caf347d2ab9dc0f7e2f8f67d","6ea0ff2626ff42209d0b91e078643b2a","600d0378e32544249989b8459b6caa4f","d4778d15bf644c5f95c2cd1393a99ade","1f1a7547b38a446e901f69bb93fd5a6a","a7219a2287884a0c945acce48091b714","86e130d64da94258be512d7e5e7a683d","decd49b6ff754d4aabff9ad3f36b190c","9ebb68e8782b472eaf07bc1c6855a260","abdf28c6ae0a4f1f80dce1edf848996d","1ed4ce3a523a460189fbdb5efd5da0ea","4923395efad2488d8287739f3856a7fb","c7ac9a36f4f7429a8e5d0ecab2351c1b","ac13d6d0fab745e6bb062199d70959b9","2ad30d8cb9694057a580b84bfa2d857f","8e33970ef68146408d5bdcd485637fbf"]},"executionInfo":{"elapsed":10220,"status":"ok","timestamp":1718001914887,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"DhLnQUJkXaJ6","outputId":"04bd9f6d-f59d-4650-c376-a1ff7ce11a22"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["RoBERTawithMiT(\n","  (text_model): PeftModel(\n","    (base_model): LoraModel(\n","      (model): RobertaModel(\n","        (embeddings): RobertaEmbeddings(\n","          (word_embeddings): Embedding(32000, 1024, padding_idx=1)\n","          (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","          (token_type_embeddings): Embedding(1, 1024)\n","          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (encoder): RobertaEncoder(\n","          (layer): ModuleList(\n","            (0-23): 24 x RobertaLayer(\n","              (attention): RobertaAttention(\n","                (self): RobertaSelfAttention(\n","                  (query): lora.Linear(\n","                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.1, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=1024, out_features=8, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=8, out_features=1024, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (key): lora.Linear(\n","                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.1, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=1024, out_features=8, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=8, out_features=1024, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (value): lora.Linear(\n","                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","                    (lora_dropout): ModuleDict(\n","                      (default): Dropout(p=0.1, inplace=False)\n","                    )\n","                    (lora_A): ModuleDict(\n","                      (default): Linear(in_features=1024, out_features=8, bias=False)\n","                    )\n","                    (lora_B): ModuleDict(\n","                      (default): Linear(in_features=8, out_features=1024, bias=False)\n","                    )\n","                    (lora_embedding_A): ParameterDict()\n","                    (lora_embedding_B): ParameterDict()\n","                  )\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","                (output): RobertaSelfOutput(\n","                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                  (dropout): Dropout(p=0.1, inplace=False)\n","                )\n","              )\n","              (intermediate): RobertaIntermediate(\n","                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","                (intermediate_act_fn): GELUActivation()\n","              )\n","              (output): RobertaOutput(\n","                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","          )\n","        )\n","        (pooler): RobertaPooler(\n","          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","          (activation): Tanh()\n","        )\n","      )\n","    )\n","  )\n","  (img_model): PeftModel(\n","    (base_model): LoraModel(\n","      (model): SegformerModel(\n","        (encoder): SegformerEncoder(\n","          (patch_embeddings): ModuleList(\n","            (0): SegformerOverlapPatchEmbeddings(\n","              (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n","              (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (1): SegformerOverlapPatchEmbeddings(\n","              (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","              (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (2): SegformerOverlapPatchEmbeddings(\n","              (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","              (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","            )\n","            (3): SegformerOverlapPatchEmbeddings(\n","              (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","              (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","            )\n","          )\n","          (block): ModuleList(\n","            (0): ModuleList(\n","              (0): SegformerLayer(\n","                (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","                (attention): SegformerAttention(\n","                  (self): SegformerEfficientSelfAttention(\n","                    (query): lora.Linear(\n","                      (base_layer): Linear(in_features=32, out_features=32, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=32, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=32, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (key): lora.Linear(\n","                      (base_layer): Linear(in_features=32, out_features=32, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=32, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=32, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (value): lora.Linear(\n","                      (base_layer): Linear(in_features=32, out_features=32, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=32, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=32, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                    (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n","                    (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","                  )\n","                  (output): SegformerSelfOutput(\n","                    (dense): Linear(in_features=32, out_features=32, bias=True)\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                  )\n","                )\n","                (drop_path): Identity()\n","                (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","                (mlp): SegformerMixFFN(\n","                  (dense1): Linear(in_features=32, out_features=128, bias=True)\n","                  (dwconv): SegformerDWConv(\n","                    (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n","                  )\n","                  (intermediate_act_fn): GELUActivation()\n","                  (dense2): Linear(in_features=128, out_features=32, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (1): SegformerLayer(\n","                (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","                (attention): SegformerAttention(\n","                  (self): SegformerEfficientSelfAttention(\n","                    (query): lora.Linear(\n","                      (base_layer): Linear(in_features=32, out_features=32, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=32, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=32, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (key): lora.Linear(\n","                      (base_layer): Linear(in_features=32, out_features=32, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=32, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=32, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (value): lora.Linear(\n","                      (base_layer): Linear(in_features=32, out_features=32, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=32, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=32, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                    (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n","                    (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","                  )\n","                  (output): SegformerSelfOutput(\n","                    (dense): Linear(in_features=32, out_features=32, bias=True)\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                  )\n","                )\n","                (drop_path): SegformerDropPath(p=0.014285714365541935)\n","                (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","                (mlp): SegformerMixFFN(\n","                  (dense1): Linear(in_features=32, out_features=128, bias=True)\n","                  (dwconv): SegformerDWConv(\n","                    (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n","                  )\n","                  (intermediate_act_fn): GELUActivation()\n","                  (dense2): Linear(in_features=128, out_features=32, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","            (1): ModuleList(\n","              (0): SegformerLayer(\n","                (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","                (attention): SegformerAttention(\n","                  (self): SegformerEfficientSelfAttention(\n","                    (query): lora.Linear(\n","                      (base_layer): Linear(in_features=64, out_features=64, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=64, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=64, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (key): lora.Linear(\n","                      (base_layer): Linear(in_features=64, out_features=64, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=64, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=64, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (value): lora.Linear(\n","                      (base_layer): Linear(in_features=64, out_features=64, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=64, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=64, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                    (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n","                    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","                  )\n","                  (output): SegformerSelfOutput(\n","                    (dense): Linear(in_features=64, out_features=64, bias=True)\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                  )\n","                )\n","                (drop_path): SegformerDropPath(p=0.02857142873108387)\n","                (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","                (mlp): SegformerMixFFN(\n","                  (dense1): Linear(in_features=64, out_features=256, bias=True)\n","                  (dwconv): SegformerDWConv(\n","                    (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","                  )\n","                  (intermediate_act_fn): GELUActivation()\n","                  (dense2): Linear(in_features=256, out_features=64, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (1): SegformerLayer(\n","                (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","                (attention): SegformerAttention(\n","                  (self): SegformerEfficientSelfAttention(\n","                    (query): lora.Linear(\n","                      (base_layer): Linear(in_features=64, out_features=64, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=64, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=64, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (key): lora.Linear(\n","                      (base_layer): Linear(in_features=64, out_features=64, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=64, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=64, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (value): lora.Linear(\n","                      (base_layer): Linear(in_features=64, out_features=64, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=64, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=64, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                    (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n","                    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","                  )\n","                  (output): SegformerSelfOutput(\n","                    (dense): Linear(in_features=64, out_features=64, bias=True)\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                  )\n","                )\n","                (drop_path): SegformerDropPath(p=0.04285714402794838)\n","                (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","                (mlp): SegformerMixFFN(\n","                  (dense1): Linear(in_features=64, out_features=256, bias=True)\n","                  (dwconv): SegformerDWConv(\n","                    (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","                  )\n","                  (intermediate_act_fn): GELUActivation()\n","                  (dense2): Linear(in_features=256, out_features=64, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","            (2): ModuleList(\n","              (0): SegformerLayer(\n","                (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","                (attention): SegformerAttention(\n","                  (self): SegformerEfficientSelfAttention(\n","                    (query): lora.Linear(\n","                      (base_layer): Linear(in_features=160, out_features=160, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=160, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=160, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (key): lora.Linear(\n","                      (base_layer): Linear(in_features=160, out_features=160, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=160, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=160, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (value): lora.Linear(\n","                      (base_layer): Linear(in_features=160, out_features=160, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=160, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=160, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                    (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n","                    (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","                  )\n","                  (output): SegformerSelfOutput(\n","                    (dense): Linear(in_features=160, out_features=160, bias=True)\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                  )\n","                )\n","                (drop_path): SegformerDropPath(p=0.05714285746216774)\n","                (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","                (mlp): SegformerMixFFN(\n","                  (dense1): Linear(in_features=160, out_features=640, bias=True)\n","                  (dwconv): SegformerDWConv(\n","                    (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n","                  )\n","                  (intermediate_act_fn): GELUActivation()\n","                  (dense2): Linear(in_features=640, out_features=160, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (1): SegformerLayer(\n","                (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","                (attention): SegformerAttention(\n","                  (self): SegformerEfficientSelfAttention(\n","                    (query): lora.Linear(\n","                      (base_layer): Linear(in_features=160, out_features=160, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=160, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=160, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (key): lora.Linear(\n","                      (base_layer): Linear(in_features=160, out_features=160, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=160, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=160, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (value): lora.Linear(\n","                      (base_layer): Linear(in_features=160, out_features=160, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=160, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=160, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                    (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n","                    (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","                  )\n","                  (output): SegformerSelfOutput(\n","                    (dense): Linear(in_features=160, out_features=160, bias=True)\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                  )\n","                )\n","                (drop_path): SegformerDropPath(p=0.0714285746216774)\n","                (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","                (mlp): SegformerMixFFN(\n","                  (dense1): Linear(in_features=160, out_features=640, bias=True)\n","                  (dwconv): SegformerDWConv(\n","                    (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n","                  )\n","                  (intermediate_act_fn): GELUActivation()\n","                  (dense2): Linear(in_features=640, out_features=160, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","            (3): ModuleList(\n","              (0): SegformerLayer(\n","                (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","                (attention): SegformerAttention(\n","                  (self): SegformerEfficientSelfAttention(\n","                    (query): lora.Linear(\n","                      (base_layer): Linear(in_features=256, out_features=256, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=256, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=256, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (key): lora.Linear(\n","                      (base_layer): Linear(in_features=256, out_features=256, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=256, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=256, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (value): lora.Linear(\n","                      (base_layer): Linear(in_features=256, out_features=256, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=256, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=256, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                  )\n","                  (output): SegformerSelfOutput(\n","                    (dense): Linear(in_features=256, out_features=256, bias=True)\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                  )\n","                )\n","                (drop_path): SegformerDropPath(p=0.08571428805589676)\n","                (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","                (mlp): SegformerMixFFN(\n","                  (dense1): Linear(in_features=256, out_features=1024, bias=True)\n","                  (dwconv): SegformerDWConv(\n","                    (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n","                  )\n","                  (intermediate_act_fn): GELUActivation()\n","                  (dense2): Linear(in_features=1024, out_features=256, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","              (1): SegformerLayer(\n","                (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","                (attention): SegformerAttention(\n","                  (self): SegformerEfficientSelfAttention(\n","                    (query): lora.Linear(\n","                      (base_layer): Linear(in_features=256, out_features=256, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=256, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=256, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (key): lora.Linear(\n","                      (base_layer): Linear(in_features=256, out_features=256, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=256, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=256, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (value): lora.Linear(\n","                      (base_layer): Linear(in_features=256, out_features=256, bias=True)\n","                      (lora_dropout): ModuleDict(\n","                        (default): Dropout(p=0.1, inplace=False)\n","                      )\n","                      (lora_A): ModuleDict(\n","                        (default): Linear(in_features=256, out_features=8, bias=False)\n","                      )\n","                      (lora_B): ModuleDict(\n","                        (default): Linear(in_features=8, out_features=256, bias=False)\n","                      )\n","                      (lora_embedding_A): ParameterDict()\n","                      (lora_embedding_B): ParameterDict()\n","                    )\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                  )\n","                  (output): SegformerSelfOutput(\n","                    (dense): Linear(in_features=256, out_features=256, bias=True)\n","                    (dropout): Dropout(p=0.0, inplace=False)\n","                  )\n","                )\n","                (drop_path): SegformerDropPath(p=0.10000000149011612)\n","                (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","                (mlp): SegformerMixFFN(\n","                  (dense1): Linear(in_features=256, out_features=1024, bias=True)\n","                  (dwconv): SegformerDWConv(\n","                    (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n","                  )\n","                  (intermediate_act_fn): GELUActivation()\n","                  (dense2): Linear(in_features=1024, out_features=256, bias=True)\n","                  (dropout): Dropout(p=0.0, inplace=False)\n","                )\n","              )\n","            )\n","          )\n","          (layer_norm): ModuleList(\n","            (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n","            (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","            (2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n","            (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (encoder_layer): TransformerEncoderLayer(\n","    (self_attn): MultiheadAttention(\n","      (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n","    )\n","    (linear1): Linear(in_features=1280, out_features=2048, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (linear2): Linear(in_features=2048, out_features=1280, bias=True)\n","    (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","    (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","    (dropout1): Dropout(p=0.1, inplace=False)\n","    (dropout2): Dropout(p=0.1, inplace=False)\n","  )\n","  (transformer_encoder): TransformerEncoder(\n","    (layers): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n","        )\n","        (linear1): Linear(in_features=1280, out_features=2048, bias=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (linear2): Linear(in_features=2048, out_features=1280, bias=True)\n","        (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n","        (dropout1): Dropout(p=0.1, inplace=False)\n","        (dropout2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (classifier): Linear(in_features=1280, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n",")"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# Model\n","model = RoBERTawithMiT(text_checkpoint, vision_checkpoint)\n","model.to(device)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":998,"status":"ok","timestamp":1718001942732,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"lGEVwYNia9ty","outputId":"bc4a4940-9de0-4e12-a663-8c96c51d880e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Trainable Params: 24851458 \n","All params: 364827234\n","--------------------------------------------------\n","Trainable(%): 6.81184\n"]}],"source":["# LoRA 적용 후 훈련 가능한 파라미터 개수\n","print_trainable_parameters(model)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"5nph3VphbBfu"},"outputs":[],"source":["# 손실함수와 옵티마이저, 그리고 Metrics\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=3e-5)\n","acc_metric = BinaryAccuracy().to(device)\n","f1_metric = BinaryF1Score().to(device)\n","precision_metric = BinaryPrecision().to(device)\n","recall_metric = BinaryRecall().to(device)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"ZcKSzcVVbD2A"},"outputs":[],"source":["# 모델 학습 파라미터\n","num_epochs = 10\n","wait_for_es = 5"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"xKoN1gTQbLyU"},"outputs":[],"source":["# Trainer 정의\n","trainer = Trainer(model,\n","                  train_dataloader,\n","                  valid_dataloader,\n","                  criterion,\n","                  optimizer,\n","                  acc_metric,\n","                  precision_metric,\n","                  recall_metric,\n","                  f1_metric,\n","                  device,\n","                  num_epochs,\n","                  wait_for_es)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":675075,"status":"ok","timestamp":1718003417100,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"U1wiGHgcbP1L","outputId":"52ec7b88-e701-4c44-a8fd-3c96a9a7de99"},"outputs":[],"source":["# 학습 시작\n","train_loss_history, train_acc_history, train_precision_history, train_recall_history, train_f1_history, valid_loss_history, valid_acc_history, valid_precision_history, valid_recall_history, valid_f1_history = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_joq5dlhSTT"},"outputs":[],"source":["# 학습 과정 시각화 함수\n","def plot_training_history(train_loss_history, train_acc_history, train_precision_history, train_recall_history, train_f1_history,\n","                          valid_loss_history, valid_acc_history, valid_precision_history, valid_recall_history, valid_f1_history):\n","    fig = plt.figure(figsize=(16, 9))\n","\n","    # Loss Plot\n","    ax1 = plt.subplot2grid((2, 4), (0, 0), colspan=4)\n","    ax1.plot(train_loss_history, label='Train Loss')\n","    ax1.plot(valid_loss_history, label='Validation Loss')\n","    ax1.set_title('Training and Validation Loss')\n","    ax1.set_xlabel('Epochs')\n","    ax1.set_ylabel('Loss')\n","    ax1.legend()\n","\n","    # Accuracy Plot\n","    ax2 = plt.subplot2grid((2, 4), (1, 0))\n","    ax2.plot(train_acc_history, label='Train Accuracy')\n","    ax2.plot(valid_acc_history, label='Validation Accuracy')\n","    ax2.set_title('Training and Validation Accuracy')\n","    ax2.set_xlabel('Epochs')\n","    ax2.set_ylabel('Accuracy')\n","    ax2.legend()\n","\n","    # Precision Plot\n","    ax3 = plt.subplot2grid((2, 4), (1, 1))\n","    ax3.plot(train_precision_history, label='Train Precision')\n","    ax3.plot(valid_precision_history, label='Validation Precision')\n","    ax3.set_title('Training and Validation Precision')\n","    ax3.set_xlabel('Epochs')\n","    ax3.set_ylabel('Precision')\n","    ax3.legend()\n","\n","    # Recall Plot\n","    ax4 = plt.subplot2grid((2, 4), (1, 2))\n","    ax4.plot(train_recall_history, label='Train Recall')\n","    ax4.plot(valid_recall_history, label='Validation Recall')\n","    ax4.set_title('Training and Validation Recall')\n","    ax4.set_xlabel('Epochs')\n","    ax4.set_ylabel('Recall')\n","    ax4.legend()\n","\n","    # F1 Plot\n","    ax5 = plt.subplot2grid((2, 4), (1, 3))\n","    ax5.plot(train_f1_history, label='Train F1 Score')\n","    ax5.plot(valid_f1_history, label='Validation F1 Score')\n","    ax5.set_title('Training and Validation F1 Score')\n","    ax5.set_xlabel('Epochs')\n","    ax5.set_ylabel('F1 Score')\n","    ax5.legend()\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":736},"executionInfo":{"elapsed":2132,"status":"ok","timestamp":1718003499509,"user":{"displayName":"이상혁","userId":"00658844908796319219"},"user_tz":-540},"id":"jr0z7yk6hs-D","outputId":"13259a33-345f-47d3-96fb-bfc20d14a403"},"outputs":[],"source":["plot_training_history(train_loss_history, train_acc_history, train_precision_history, train_recall_history, train_f1_history, valid_loss_history, valid_acc_history, valid_precision_history, valid_recall_history, valid_f1_history)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 모델 로드 함수 정의\n","def load_model(model_path, text_checkpoint, vision_checkpoint):\n","    model = RoBERTawithMiT(text_checkpoint, vision_checkpoint)\n","    model.load_state_dict(torch.load(model_path))\n","    model.to(device)\n","    return model\n","\n","# Inference 함수 정의\n","def inference(model, test_dataloader, device):\n","    model.eval()\n","\n","    preds_list = []\n","    true_labels = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(test_dataloader, desc='Testing'):\n","            input_ids, attention_mask, pixel_values, y = batch\n","            input_ids, attention_mask, pixel_values, y = input_ids.to(device), attention_mask.to(device), pixel_values.to(device), y.to(device)\n","\n","            outputs = model(input_ids, attention_mask, pixel_values)\n","            preds = torch.argmax(outputs, dim=1)\n","\n","            preds_list.extend(preds.cpu().numpy())\n","            true_labels.extend(y.cpu().numpy())\n","\n","    return preds_list, true_labels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 저장된 모델 경로\n","best_model_path = path+''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 모델 불러오기\n","model = load_model(best_model_path, text_checkpoint, vision_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["preds_list, true_labels = inference(model, test_dataloader, device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 평가 지표 계산\n","test_accuracy = accuracy_score(true_labels, preds_list)\n","test_precision = precision_score(true_labels, preds_list)\n","test_recall = recall_score(true_labels, preds_list)\n","test_f1 = f1_score(true_labels, preds_list)\n","test_cm = confusion_matrix(true_labels, preds_list)\n","\n","print(f'Test Accuracy: {test_accuracy:.4f}')\n","print(f'Test Precision: {test_precision:.4f}')\n","print(f'Test Recall: {test_recall:.4f}')\n","print(f'Test F1 Score: {test_f1:.4f}')\n","print(f'Test Confusion Matrix: \\n{test_cm}')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOd0QULOaG4DWYLR1Uw6Gte","gpuType":"L4","machine_shape":"hm","mount_file_id":"1bcp2i7N17bU_ar6TejmtJ_C4vcg2rBlB","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"05ad48b549a74363b45ed162195f23f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0624914bb8e441b489c5b02b718e5d9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d413c7e62d594a1b9d3478c929785462","placeholder":"​","style":"IPY_MODEL_cdca1e7573304150bdfd739f9e193cce","value":" 752k/752k [00:00&lt;00:00, 3.24MB/s]"}},"0ddd353782a4448881a68400fadf4288":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_275a743ae76f4ec5ba6e4dfff871b8f8","max":248477,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbb0b5836e5e44dc8aa4eec94c76e906","value":248477}},"0e0a1902e72a4cd282ea551dd2de7f63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e8eab51253140cab747ea43c82e1493":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ea0ff2626ff42209d0b91e078643b2a","max":69665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_600d0378e32544249989b8459b6caa4f","value":69665}},"0ec6d0d8c7ec4e6e84c1db64e0dab5fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b706de7f1974d019f00c0886c040c93","placeholder":"​","style":"IPY_MODEL_49c7892db8de4de68803fb3d6f687371","value":"special_tokens_map.json: 100%"}},"114c621ffd2f43eaaefc5bbe02f5e4cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19001101177f465eaabaf7ba4948bc6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ad561646a1f44faaf62e1e193133c32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e03c962ba894ca3a08203fd853f2e60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ed4ce3a523a460189fbdb5efd5da0ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f1a7547b38a446e901f69bb93fd5a6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f398eb7136b4c7f95dc7987db6ecafa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22299453ce11485aaef6f7acae14e9d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2316a1c3d2b84c94ba3b816e468fcc8e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"269796c6b7034c7099f967abf92ae7ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"275a743ae76f4ec5ba6e4dfff871b8f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27eed056870f44e6b33faa35edbceb9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6dc1702c30b4b56b231ecb67511abf2","placeholder":"​","style":"IPY_MODEL_05ad48b549a74363b45ed162195f23f4","value":" 160/160 [00:00&lt;00:00, 11.8kB/s]"}},"2ad30d8cb9694057a580b84bfa2d857f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c14ffbc9af94a86969e4bb355c0f8cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5c6cfdfaa644a81ba362a0a91cfe80f","placeholder":"​","style":"IPY_MODEL_2d58d9d9caf347d2ab9dc0f7e2f8f67d","value":"config.json: 100%"}},"2d58d9d9caf347d2ab9dc0f7e2f8f67d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e8c3c52ad1b468c82615f89e14826b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2316a1c3d2b84c94ba3b816e468fcc8e","placeholder":"​","style":"IPY_MODEL_b400db3135534cc8862f474e72b2fb52","value":"preprocessor_config.json: 100%"}},"327914875a464c828f73a942b7a6a76d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"347a8274bdb54ca8a5a7e89b48870129":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_533b5eaeb77349cf99fe9b4f841d3792","IPY_MODEL_f2cf3f33489142749d7679ffeea51270","IPY_MODEL_0624914bb8e441b489c5b02b718e5d9a"],"layout":"IPY_MODEL_22299453ce11485aaef6f7acae14e9d8"}},"349b0743813c449e90c56bef8eacb9a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b58b8e79716745b8b370074f07d03cf0","max":547,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e0a1902e72a4cd282ea551dd2de7f63","value":547}},"34faa1f4ba3842ab9e718dec8f5191d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4778d15bf644c5f95c2cd1393a99ade","placeholder":"​","style":"IPY_MODEL_1f1a7547b38a446e901f69bb93fd5a6a","value":" 69.7k/69.7k [00:00&lt;00:00, 5.42MB/s]"}},"38272f22ffef4216926f30ea7dabc470":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fe64ed868a8449b8a93afa368c9ace2","placeholder":"​","style":"IPY_MODEL_1f398eb7136b4c7f95dc7987db6ecafa","value":" 173/173 [00:00&lt;00:00, 16.2kB/s]"}},"431181882470458c861b502da88cbbc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4923395efad2488d8287739f3856a7fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"494c8c49bb4342428114da3ffa7faf7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49c7892db8de4de68803fb3d6f687371":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51f8b03224f140bb857153483e96842d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"533b5eaeb77349cf99fe9b4f841d3792":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ceb3f06c3e474dac9288978a208e057c","placeholder":"​","style":"IPY_MODEL_51f8b03224f140bb857153483e96842d","value":"tokenizer.json: 100%"}},"578e388fc32642e5ac305b8381ac1e4a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ab57db8244546b9b4fa74d887e4a7c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c55426784c884206bd9ec6b2778868a6","IPY_MODEL_349b0743813c449e90c56bef8eacb9a1","IPY_MODEL_d4613f0edca84df7a62d0329f910ca55"],"layout":"IPY_MODEL_e1418eb477114bc697cfd013353ebf4e"}},"5bdac34142f44af494316c16b72cfb12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_96cf0b7cd2054a44afb1f8d08fbb23db","IPY_MODEL_6004a9763595414bb448e93736855d22","IPY_MODEL_f1b0ab561bfa41b5a73cdba015a8a8de"],"layout":"IPY_MODEL_578e388fc32642e5ac305b8381ac1e4a"}},"5e70b95e73cf45f6bd58628862e2627a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6004a9763595414bb448e93736855d22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f25e3f27104747a3823ac47d1bf89d4d","max":375,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94cecbf9794c49fdad80d7527365357a","value":375}},"600d0378e32544249989b8459b6caa4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6435fffa801b449ba5df6b2cc4150298":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69ae0998628e422eb96470e4ad655f09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69edc96c74624b3bb2b0119168aefedd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e03c962ba894ca3a08203fd853f2e60","placeholder":"​","style":"IPY_MODEL_19001101177f465eaabaf7ba4948bc6e","value":"vocab.txt: 100%"}},"6bfdbce1e7594fd59f8d481ba30abfd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ea0ff2626ff42209d0b91e078643b2a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fe64ed868a8449b8a93afa368c9ace2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"792c5c05251f4b34aef67fdf8b6567a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e35e6e83b084964b8a7458c0e7fda42":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86e130d64da94258be512d7e5e7a683d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ed4ce3a523a460189fbdb5efd5da0ea","placeholder":"​","style":"IPY_MODEL_4923395efad2488d8287739f3856a7fb","value":"model.safetensors: 100%"}},"89850ceba93d4524a01f42a569c83e13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b706de7f1974d019f00c0886c040c93":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b9a4796504640a39f88de8ecd02f016":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dcfafcec94746cfb0d7a03fbef79fbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b08acb98d58f4a8692030f0b875b6289","placeholder":"​","style":"IPY_MODEL_b2f242ac94284a8bbb3d575387d70e54","value":" 248k/248k [00:00&lt;00:00, 363kB/s]"}},"8e33970ef68146408d5bdcd485637fbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e363762c5be48b6bfe9fedb52f9e05e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c14ffbc9af94a86969e4bb355c0f8cd","IPY_MODEL_0e8eab51253140cab747ea43c82e1493","IPY_MODEL_34faa1f4ba3842ab9e718dec8f5191d3"],"layout":"IPY_MODEL_8b9a4796504640a39f88de8ecd02f016"}},"8ef1d75b9c8841a5b9dbd2b40b3f74f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90b7dee96efc4df89e1975f5df903925":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91344e321a9b455d8f0624d03288b5eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"920bb65bedbc43888a2a97b65a02dd91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69edc96c74624b3bb2b0119168aefedd","IPY_MODEL_0ddd353782a4448881a68400fadf4288","IPY_MODEL_8dcfafcec94746cfb0d7a03fbef79fbe"],"layout":"IPY_MODEL_90b7dee96efc4df89e1975f5df903925"}},"94cecbf9794c49fdad80d7527365357a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"96cf0b7cd2054a44afb1f8d08fbb23db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69ae0998628e422eb96470e4ad655f09","placeholder":"​","style":"IPY_MODEL_cb5e76fc03584709a8e94de68c3e97c3","value":"tokenizer_config.json: 100%"}},"9ebb68e8782b472eaf07bc1c6855a260":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ad30d8cb9694057a580b84bfa2d857f","placeholder":"​","style":"IPY_MODEL_8e33970ef68146408d5bdcd485637fbf","value":" 346M/346M [00:00&lt;00:00, 563MB/s]"}},"a66dcfc200f34bafa7738af46574b6fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_89850ceba93d4524a01f42a569c83e13","max":173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91344e321a9b455d8f0624d03288b5eb","value":173}},"a6d5ee785f9040cb9da60ec576f82e53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e8c3c52ad1b468c82615f89e14826b1","IPY_MODEL_e76c9795113848dca5d946aae0374804","IPY_MODEL_27eed056870f44e6b33faa35edbceb9c"],"layout":"IPY_MODEL_fcab8208928944efb75f604862361f54"}},"a7219a2287884a0c945acce48091b714":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86e130d64da94258be512d7e5e7a683d","IPY_MODEL_decd49b6ff754d4aabff9ad3f36b190c","IPY_MODEL_9ebb68e8782b472eaf07bc1c6855a260"],"layout":"IPY_MODEL_abdf28c6ae0a4f1f80dce1edf848996d"}},"ab065a9873244e40a6b6390e0547245c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ef1d75b9c8841a5b9dbd2b40b3f74f3","max":1346814194,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d909c83b089b4c29a7f42eab7c8d31c8","value":1346814194}},"ab122c513e1f4010974bad603d341782":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ec6d0d8c7ec4e6e84c1db64e0dab5fa","IPY_MODEL_a66dcfc200f34bafa7738af46574b6fb","IPY_MODEL_38272f22ffef4216926f30ea7dabc470"],"layout":"IPY_MODEL_b4ec8ccc5ba44233bff06c203893beb1"}},"abdf28c6ae0a4f1f80dce1edf848996d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac13d6d0fab745e6bb062199d70959b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b08acb98d58f4a8692030f0b875b6289":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2f242ac94284a8bbb3d575387d70e54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b400db3135534cc8862f474e72b2fb52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4ec8ccc5ba44233bff06c203893beb1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b58b8e79716745b8b370074f07d03cf0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b83f9b62de3d4646a6bf81edd8e34f9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf59ec9765844db09f7ca03fe1e1355b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_431181882470458c861b502da88cbbc3","placeholder":"​","style":"IPY_MODEL_b83f9b62de3d4646a6bf81edd8e34f9b","value":" 1.35G/1.35G [00:02&lt;00:00, 466MB/s]"}},"c55426784c884206bd9ec6b2778868a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbcc5b2ac63f4fbd828307b3df0ae007","placeholder":"​","style":"IPY_MODEL_cd12fd03a5e94f6284ee141001595d8c","value":"config.json: 100%"}},"c7ac9a36f4f7429a8e5d0ecab2351c1b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8ab35e93fd34caf996c05ca0f46baba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb5e76fc03584709a8e94de68c3e97c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbb0b5836e5e44dc8aa4eec94c76e906":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd12fd03a5e94f6284ee141001595d8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdca1e7573304150bdfd739f9e193cce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ceb3f06c3e474dac9288978a208e057c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d413c7e62d594a1b9d3478c929785462":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4613f0edca84df7a62d0329f910ca55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_494c8c49bb4342428114da3ffa7faf7e","placeholder":"​","style":"IPY_MODEL_6bfdbce1e7594fd59f8d481ba30abfd5","value":" 547/547 [00:00&lt;00:00, 51.7kB/s]"}},"d4778d15bf644c5f95c2cd1393a99ade":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5c6cfdfaa644a81ba362a0a91cfe80f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d909c83b089b4c29a7f42eab7c8d31c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"decd49b6ff754d4aabff9ad3f36b190c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7ac9a36f4f7429a8e5d0ecab2351c1b","max":346293852,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac13d6d0fab745e6bb062199d70959b9","value":346293852}},"e1418eb477114bc697cfd013353ebf4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5ce1d91567f4c949cfea93b72f4478e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e70b95e73cf45f6bd58628862e2627a","placeholder":"​","style":"IPY_MODEL_c8ab35e93fd34caf996c05ca0f46baba","value":"model.safetensors: 100%"}},"e76c9795113848dca5d946aae0374804":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_327914875a464c828f73a942b7a6a76d","max":160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_114c621ffd2f43eaaefc5bbe02f5e4cf","value":160}},"f1b0ab561bfa41b5a73cdba015a8a8de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ad561646a1f44faaf62e1e193133c32","placeholder":"​","style":"IPY_MODEL_792c5c05251f4b34aef67fdf8b6567a1","value":" 375/375 [00:00&lt;00:00, 29.7kB/s]"}},"f25e3f27104747a3823ac47d1bf89d4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2cf3f33489142749d7679ffeea51270":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6435fffa801b449ba5df6b2cc4150298","max":751504,"min":0,"orientation":"horizontal","style":"IPY_MODEL_269796c6b7034c7099f967abf92ae7ec","value":751504}},"f6dc1702c30b4b56b231ecb67511abf2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbcc5b2ac63f4fbd828307b3df0ae007":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcab8208928944efb75f604862361f54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fccf9be0b52f4cc1b1e3f755422d7693":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5ce1d91567f4c949cfea93b72f4478e","IPY_MODEL_ab065a9873244e40a6b6390e0547245c","IPY_MODEL_bf59ec9765844db09f7ca03fe1e1355b"],"layout":"IPY_MODEL_7e35e6e83b084964b8a7458c0e7fda42"}}}}},"nbformat":4,"nbformat_minor":0}
